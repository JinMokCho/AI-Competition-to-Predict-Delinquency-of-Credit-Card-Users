# 신용카드 연체 예측 프로젝트

## 📚 프로젝트 개요
이 프로젝트는 신용카드 사용자의 연체 여부를 예측하기 위한 머신러닝 모델을 개발하는 것입니다. 다양한 모델을 활용하고, 데이터 전처리 및 특성 엔지니어링을 통해 모델의 성능을 극대화하는 것을 목표로 하였습니다.

## 📊 변수 설명

| 변수 이름         | 설명                                                      |
|-------------------|-----------------------------------------------------------|
| `child_num`       | 자녀 수                                                  |
| `income_total`    | 총 수입                                                  |
| `DAYS_BIRTH`      | 생년월일로부터의 일수 (과거 값, 값이 클수록 나이가 많음) |
| `DAYS_EMPLOYED`   | 고용된 날로부터의 일수 (과거 값, 값이 클수록 경력이 많음) |
| `work_phone`      | 직장 전화 소지 여부 (0: 없음, 1: 있음)                 |
| `phone`           | 개인 전화 소지 여부 (0: 없음, 1: 있음)                  |
| `email`           | 이메일 소지 여부 (0: 없음, 1: 있음)                     |
| `family_size`     | 가족 규모                                               |
| `gender`          | 성별 (0: 여성, 1: 남성)                                 |
| `car`             | 차량 소유 여부 (0: 없음, 1: 있음)                       |
| `reality`         | 부동산 소유 여부 (0: 없음, 1: 있음)                     |
| `income_type`     | 수입 유형 (예: 급여, 자영업 등)                          |
| `edu_type`        | 교육 수준 (예: 고졸, 대졸 등)                            |
| `family_type`     | 가족 형태 (예: 단독, 핵가족 등)                          |
| `house_type`      | 주택 유형 (예: 소유, 임대 등)                            |
| `occyp_type`      | 직업 유형                                               |
| `ID`              | 고유 사용자 식별자 (여러 컬럼 값을 결합하여 생성)      |


## 🔧 데이터 전처리
- **결측치 처리**: 데이터셋의 결측치를 적절히 처리하여 모델 학습에 적합한 형태로 변환했습니다.
- **범주형 변수 인코딩**: 성별, 차량 소유 여부, 부동산 소유 여부 등 범주형 변수를 이진형 변수로 변환했습니다.
- **로그 변환**: 수입 컬럼에 로그 변환을 적용하여 비대칭 분포를 개선했습니다.
- **정수형 변환**: 특정 컬럼을 정수형으로 변환하여 모델 학습에 적합한 형태로 변환했습니다.
- **원-핫 인코딩**: 범주형 변수를 원-핫 인코딩하여 모델이 이해할 수 있는 형태로 변환했습니다.

## ⚙️ 모델링
- 다양한 머신러닝 모델을 시도하였고, XGBoost 모델이 가장 높은 성능을 보였습니다.
- **AutoML**: AutoGluon을 활용하여 여러 모델을 자동으로 학습하고 평가하였습니다.
- **하이퍼파라미터 튜닝**: Optuna를 사용하여 LGBMClassifier의 하이퍼파라미터를 최적화하였습니다.

## 🛠️ 변수 생성
리더보드 점수가 높은 모델들에서 'ID'라는 변수를 생성한 것을 발견했습니다. 이 변수는 여러 컬럼의 값을 결합하여 고유한 사용자를 식별하기 위해 만들어졌습니다. 이를 통해 다음과 같은 인사이트를 얻었습니다:
- 변수 생성이 모델 성능에 큰 영향을 미친다는 것을 확인하였습니다.
- 특성 엔지니어링의 중요성을 다시 한 번 깨닫게 되었습니다.

## 📈 최종 성과
- 최종 모델은 랜덤 서치로 튜닝한 XGBoost 모델로, 퍼블릭 점수는 **0.7377**, 프라이빗 점수는 **0.7115**를 기록하였습니다.

## 💡 결론
이번 프로젝트를 통해 데이터 전처리, 모델링, 하이퍼파라미터 튜닝, 그리고 특성 엔지니어링의 중요성을 깊이 이해할 수 있었습니다. 향후 데이터 분석 및 모델링 작업에 큰 도움이 될 것입니다.

## 📦 사용한 라이브러리
- `pandas`
- `numpy`
- `scikit-learn`
- `XGBoost`
- `LightGBM`
- `AutoGluon`
- `Optuna`
- `SHAP`

